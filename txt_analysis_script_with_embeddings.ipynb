{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Citation Assistant for Buddhist AI Paper\n",
    "\n",
    "\n",
    "\n",
    " This notebook creates acknowledgment sentences and citations based on Daniel's edit comments.\n",
    "\n",
    " It will help you acknowledge the existence of scholarly works without claiming deep familiarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import openai\n",
    "import anthropic\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\", \"\")\n",
    "\n",
    "# Set API keys\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "claude_client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Define Daniel's Edit Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daniel's edit comments with their context\n",
    "DANIEL_EDITS = [\n",
    "    {\n",
    "        \"id\": \"buddhist_epistemology\",\n",
    "        \"comment\": \"For this particular point—pattern recognition in the absence of discrete facts—I think you definitely want to consult the edited volume Apoha: Buddhist Nominalism and Human Cognition. Dunne also has a nice summary in his article entitled something like 'Key Points in Dharmakīrti's Apoha Theory.'\",\n",
    "        \"context\": \"In LLMs, meaning emerges from relationship patterns rather than discrete facts.\",\n",
    "        \"section\": \"2. Beyond Databases: Considering Vector Spaces as Epistemological Frameworks\",\n",
    "        \"files\": [\"Apoha-Buddhist Nominalism and Human Cognition\", \"Dunne_J_Key_Features_of_Dharmakirtis_Apoha_Theory\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"dignaga_dharmakirti\",\n",
    "        \"comment\": \"Dates for these, and citations. For citations, the most recent book on Digṅāga I'm aware of is Digṅāga's Investigation of the Percept (certainly relevant here). For Dharmakīrti I recommend Dunne or Tillemans in this case. Dan Arnold's twin books—one on Digṅāga, the other on Dharmakīrti—also come to mind.\",\n",
    "        \"context\": \"specifically the epistemological tradition (pramāṇavāda) developed by Digṅāga and Dharmakīrti\",\n",
    "        \"section\": \"2. Beyond Databases: Considering Vector Spaces as Epistemological Frameworks\",\n",
    "        \"files\": [\"Dan Arnold - Brains, Buddhas, and Believing\", \"Dreyfus_RecognizingReality\", \"Dunne_Foundations\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"embodiment\",\n",
    "        \"comment\": \"Personally, I'd love to see a footnote here—maybe a reference to Diane's paper in this volume, or to Michael Radich, or even to earlier work like Thompson and Varela.\",\n",
    "        \"context\": \"This exploration examines conventional embodiment requirements for awakened manifestation.\",\n",
    "        \"section\": \"Introduction\",\n",
    "        \"files\": [\"DDenis. AI.April.2025\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"sensory_liberation\",\n",
    "        \"comment\": \"Good. You might cite James Gentry's book on Power Objects here (or mention that you cite him below). I also recommend Peter Woods' recent RYI MA thesis which explores 'liberation by wearing, tasting, hearing, seeing' explicitly\",\n",
    "        \"context\": \"Historical precedents—particularly Tibetan 'liberation through sensory encounters' practices—provide frameworks for considering how awakened presence might potentially manifest through various means.\",\n",
    "        \"section\": \"Introduction\",\n",
    "        \"files\": [\"Peter-Woods-MA-Thesis-2022\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"buddha_nature\",\n",
    "        \"comment\": \"in Mahāyāna this means the complete perfection of wisdom and means; I think you're speaking more about Vajrayāna/Mahāmudrā/Dzogchen, so it might be good to just be clear on that.\",\n",
    "        \"context\": \"Just as tathagatagarbha represents the potential for awakening that manifests through specific and appropriate causes and conditions\",\n",
    "        \"section\": \"3. Exploring AI as Potential Manifestation Vehicle\",\n",
    "        \"files\": [\"Dreyfus_RecognizingReality\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"mirror_concept\",\n",
    "        \"comment\": \"Citation? Perhaps A Mirror is for Reflection (edited volume)?\",\n",
    "        \"context\": \"Just as the Buddha taught that dharma functions as a mirror reflecting one's own mind (dharmādāsa)\",\n",
    "        \"section\": \"5. Mathematical Integration and Cross-Disciplinary Knowledge Transfer\",\n",
    "        \"files\": [\"Jake H. Davis, Owen Flanagan - A mirror is for reflection\"]\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"comparative_religion\",\n",
    "        \"comment\": \"If you wanted to be unbelievably thorough here, you might reference that this is precisely Mircea Eliade's method in, e.g., Patterns in Comparative Religion. Eliade (culprit-weather example), but in terms of comparative religion/detextualizing them to make comparison. possibly cite...A Magic Still Dwells Patton, Kimberly.\",\n",
    "        \"context\": \"reducing complex Buddhist philosophical concepts to vector representations necessarily involves significant simplification, potentially losing contextual and cultural dimensions\",\n",
    "        \"section\": \"5. Mathematical Integration and Cross-Disciplinary Knowledge Transfer\",\n",
    "        \"files\": [\"A Magic Still Dwells Comparative Religion in the Postmodern Age\"]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load all available text files\n",
    "def load_all_texts(directory=\".\"):\n",
    "    all_texts = {}\n",
    "    text_files = glob.glob(f\"{directory}/*.txt\")\n",
    "    \n",
    "    for file_path in text_files:\n",
    "        file_name = Path(file_path).stem\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                all_texts[file_name] = f.read()\n",
    "            print(f\"Loaded text from: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    return all_texts\n",
    "\n",
    "# Function to load all available embeddings\n",
    "def load_all_embeddings(directory=\".\"):\n",
    "    all_embeddings = {}\n",
    "    embedding_files = glob.glob(f\"{directory}/*_embeddings.json\")\n",
    "    \n",
    "    for file_path in embedding_files:\n",
    "        file_name = Path(file_path).stem.replace(\"_embeddings\", \"\")\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                all_embeddings[file_name] = json.load(f)\n",
    "            print(f\"Loaded embeddings from: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    \n",
    "    return all_embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Search Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search for relevant passages in text\n",
    "def text_search(query, texts_dict, target_files=None):\n",
    "    if target_files:\n",
    "        # Filter to only the specified files\n",
    "        texts_dict = {k: v for k, v in texts_dict.items() if any(target in k for target in target_files)}\n",
    "    \n",
    "    if not texts_dict:\n",
    "        return []\n",
    "    \n",
    "    # Simple keyword search as fallback\n",
    "    results = []\n",
    "    \n",
    "    for doc_name, text in texts_dict.items():\n",
    "        # Split into paragraphs\n",
    "        paragraphs = text.split('\\n\\n')\n",
    "        \n",
    "        for i, para in enumerate(paragraphs):\n",
    "            # Check if query keywords are in the paragraph\n",
    "            query_words = query.lower().split()\n",
    "            word_matches = sum(1 for word in query_words if word.lower() in para.lower())\n",
    "            \n",
    "            if word_matches >= len(query_words) // 2:  # At least half of the words match\n",
    "                results.append({\n",
    "                    \"document\": doc_name,\n",
    "                    \"paragraph\": para,\n",
    "                    \"paragraph_index\": i,\n",
    "                    \"relevance\": word_matches / len(query_words)\n",
    "                })\n",
    "    \n",
    "    # Sort by relevance\n",
    "    results.sort(key=lambda x: x[\"relevance\"], reverse=True)\n",
    "    \n",
    "    return results[:3]  # Return top 3 results\n",
    "\n",
    "# Function to search for relevant passages using embeddings\n",
    "def semantic_search(query, embeddings_dict, target_files=None, top_n=3):\n",
    "    if target_files:\n",
    "        # Filter to only the specified files\n",
    "        embeddings_dict = {k: v for k, v in embeddings_dict.items() if any(target in k for target in target_files)}\n",
    "    \n",
    "    if not embeddings_dict:\n",
    "        return []\n",
    "    \n",
    "    # Get embedding for the query\n",
    "    try:\n",
    "        response = openai.embeddings.create(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            input=query\n",
    "        )\n",
    "        query_embedding = response.data[0].embedding\n",
    "        query_embedding_array = np.array(query_embedding)\n",
    "        \n",
    "        # Search across all documents\n",
    "        all_results = []\n",
    "        \n",
    "        for doc_name, embeddings in embeddings_dict.items():\n",
    "            for item in embeddings:\n",
    "                embed_array = np.array(item[\"embedding\"])\n",
    "                # Cosine similarity\n",
    "                similarity = np.dot(query_embedding_array, embed_array) / (\n",
    "                    np.linalg.norm(query_embedding_array) * np.linalg.norm(embed_array)\n",
    "                )\n",
    "                \n",
    "                all_results.append({\n",
    "                    \"document\": doc_name,\n",
    "                    \"chunk\": item[\"chunk\"],\n",
    "                    \"similarity\": float(similarity),\n",
    "                    \"chunk_index\": item[\"chunk_index\"]\n",
    "                })\n",
    "        \n",
    "        # Sort by similarity\n",
    "        all_results.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "        \n",
    "        return all_results[:top_n]\n",
    "    except Exception as e:\n",
    "        print(f\"Error in semantic search: {e}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Citation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate acknowledgment sentence and citation\n",
    "def generate_acknowledgment(edit_info, passages, text_files):\n",
    "    # Extract basic information about the source documents\n",
    "    source_details = []\n",
    "    \n",
    "    for passage in passages:\n",
    "        doc_name = passage.get(\"document\")\n",
    "        if \"chunk\" in passage:\n",
    "            content = passage.get(\"chunk\", \"\")\n",
    "        else:\n",
    "            content = passage.get(\"paragraph\", \"\")\n",
    "        \n",
    "        # Try to extract author information from the document name or content\n",
    "        author_match = re.search(r'(\\w+),?\\s+(\\w+\\.?)', doc_name)\n",
    "        author = author_match.group(1) if author_match else doc_name.split('-')[0].split(' ')[0]\n",
    "        \n",
    "        # Try to extract year from content\n",
    "        year_match = re.search(r'\\b(19|20)\\d{2}\\b', content[:500])\n",
    "        year = year_match.group(0) if year_match else \"n.d.\"\n",
    "        \n",
    "        # Try to extract title\n",
    "        title = doc_name\n",
    "        if \" - \" in doc_name:\n",
    "            title = doc_name.split(\" - \")[1]\n",
    "        elif \"_\" in doc_name:\n",
    "            title = doc_name.replace(\"_\", \" \")\n",
    "        \n",
    "        source_details.append({\n",
    "            \"document\": doc_name,\n",
    "            \"author\": author,\n",
    "            \"year\": year,\n",
    "            \"title\": title,\n",
    "            \"content_sample\": content[:300]  # First 300 chars for context\n",
    "        })\n",
    "    \n",
    "    # Create prompt for Claude to generate acknowledgment and citation\n",
    "    source_info = \"\"\n",
    "    for i, s in enumerate(source_details):\n",
    "        source_info += f\"Source {i+1}: {s['document']}\\n\"\n",
    "        source_info += f\"Content sample: {s['content_sample']}...\\n\\n\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    I'm writing an academic paper on AI and Buddhist wisdom. My editor has suggested acknowledging certain works in the scholarly conversation without claiming deep familiarity with them.\n",
    "\n",
    "    Here's the editor's comment: \"{edit_info['comment']}\"\n",
    "    \n",
    "    It refers to this sentence in my paper: \"{edit_info['context']}\"\n",
    "    \n",
    "    This appears in section: \"{edit_info['section']}\"\n",
    "\n",
    "    I have found relevant passages from these sources:\n",
    "\n",
    "    {source_info}\n",
    "\n",
    "    Please help me with:\n",
    "    \n",
    "    1. A brief (1-2 sentence) acknowledgment that mentions these works exist in the scholarly conversation and their general relevance to my point\n",
    "    2. Properly formatted Chicago-style in-text citations for these works\n",
    "    3. Complete bibliography entries for each work\n",
    "\n",
    "    The acknowledgment should:\n",
    "    - Be appropriate for inserting near the editor's comment\n",
    "    - Simply nod to the existence of these works rather than claiming deep engagement\n",
    "    - Connect to my paper's point about {edit_info['id'].replace('_', ' ')}\n",
    "    - Be concise (max 2 sentences)\n",
    "    - Use academic but accessible language\n",
    "\n",
    "    Format your response in two clear sections:\n",
    "    1. ACKNOWLEDGMENT: (your 1-2 sentence acknowledgment with in-text citations)\n",
    "    2. BIBLIOGRAPHY: (one bibliography entry per line)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use Claude to generate the acknowledgment and citations\n",
    "    try:\n",
    "        message = claude_client.messages.create(\n",
    "            model=\"claude-3-opus-20240229\",\n",
    "            max_tokens=1000,\n",
    "            temperature=0.2,\n",
    "            system=\"You are a helpful academic writing assistant with expertise in Buddhist studies and Chicago citation format.\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        response_text = message.content[0].text\n",
    "        \n",
    "        # Parse the response manually instead of relying on JSON\n",
    "        acknowledgment = \"\"\n",
    "        bibliography = []\n",
    "        \n",
    "        if \"ACKNOWLEDGMENT:\" in response_text:\n",
    "            parts = response_text.split(\"BIBLIOGRAPHY:\")\n",
    "            if len(parts) > 0:\n",
    "                ack_part = parts[0].split(\"ACKNOWLEDGMENT:\")[1].strip()\n",
    "                acknowledgment = ack_part\n",
    "            \n",
    "            if len(parts) > 1:\n",
    "                bib_part = parts[1].strip()\n",
    "                bibliography = [line.strip() for line in bib_part.split(\"\\n\") if line.strip()]\n",
    "        \n",
    "        return {\n",
    "            \"acknowledgment\": acknowledgment,\n",
    "            \"bibliography\": bibliography\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating acknowledgment with Claude: {e}\")\n",
    "        # Fallback to a simple acknowledgment\n",
    "        return {\n",
    "            \"acknowledgment\": f\"Scholars have addressed {edit_info['id'].replace('_', ' ')} in works such as {', '.join([s['document'] for s in source_details])}.\",\n",
    "            \"bibliography\": [f\"{s['document']}.\" for s in source_details]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Main Process - Load Files and Process Daniel's Edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text files and embeddings...\n",
      "Loaded text from: A Magic Still Dwells Comparative Religion in the Postmodern Age\n",
      "Loaded text from: Apoha-Buddhist Nominalism and Human Cognition\n",
      "Loaded text from: Dan Arnold - Brains, Buddhas, and Believing - The Problem of Intentionality in Classical Buddhist and Cognitive-Scientific Philo\n",
      "Loaded text from: Dreyfus_RecognizingReality\n",
      "Loaded text from: Dunne_Foundations FDP smaller file\n",
      "Loaded text from: Dunne_J_Key_Features_of_Dharmakirtis_Apoha_Theory\n",
      "Loaded text from: Jake H. Davis, Owen Flanagan - A mirror is for reflection _ understanding Buddhist ethics-Oxford University Press (2017)\n",
      "Loaded text from: Peter-Woods-MA-Thesis-2022\n",
      "Loaded embeddings from: Apoha-Buddhist Nominalism and Human Cognition\n",
      "Loaded embeddings from: Dan Arnold - Brains, Buddhas, and Believing - The Problem of Intentionality in Classical Buddhist and Cognitive-Scientific Philo\n",
      "Loaded embeddings from: Dreyfus_RecognizingReality\n",
      "Loaded embeddings from: Dunne_Foundations FDP smaller file\n",
      "Loaded embeddings from: Dunne_J_Key_Features_of_Dharmakirtis_Apoha_Theory\n",
      "Loaded embeddings from: Jake H. Davis, Owen Flanagan - A mirror is for reflection _ understanding Buddhist ethics-Oxford University Press (2017)\n",
      "Loaded embeddings from: Peter-Woods-MA-Thesis-2022\n",
      "\n",
      "Found 8 text files and 7 embedding files.\n"
     ]
    }
   ],
   "source": [
    "# Load text files and embeddings\n",
    "print(\"Loading text files and embeddings...\")\n",
    "text_files = load_all_texts()\n",
    "embeddings = load_all_embeddings()\n",
    "\n",
    "if not text_files and not embeddings:\n",
    "    print(\"No text files or embeddings found. Please make sure the PDF extraction script has completed.\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(text_files)} text files and {len(embeddings)} embedding files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Process Each Edit Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Daniel's edit comments...\n",
      "\n",
      "Processing: buddhist_epistemology\n",
      "  Using semantic search with embeddings...\n",
      "  Found 3 relevant passages\n",
      "\n",
      "Processing: dignaga_dharmakirti\n",
      "  Using semantic search with embeddings...\n",
      "  Found 3 relevant passages\n",
      "\n",
      "Processing: embodiment\n",
      "  Using semantic search with embeddings...\n",
      "  Falling back to text search...\n",
      "  No relevant passages found for embodiment\n",
      "\n",
      "Processing: sensory_liberation\n",
      "  Using semantic search with embeddings...\n",
      "  Found 3 relevant passages\n",
      "\n",
      "Processing: buddha_nature\n",
      "  Using semantic search with embeddings...\n",
      "  Found 3 relevant passages\n",
      "\n",
      "Processing: mirror_concept\n",
      "  Using semantic search with embeddings...\n",
      "  Found 3 relevant passages\n",
      "\n",
      "Processing: comparative_religion\n",
      "  Using semantic search with embeddings...\n",
      "  Falling back to text search...\n",
      "  No relevant passages found for comparative_religion\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "print(\"\\nProcessing Daniel's edit comments...\")\n",
    "for edit in DANIEL_EDITS:\n",
    "    print(f\"\\nProcessing: {edit['id']}\")\n",
    "    edit_id = edit['id']\n",
    "    \n",
    "    # Combine the context and comment for better search results\n",
    "    search_query = f\"{edit['context']} {edit['comment']}\"\n",
    "    \n",
    "    # Try semantic search first if embeddings are available\n",
    "    passages = []\n",
    "    if embeddings:\n",
    "        print(\"  Using semantic search with embeddings...\")\n",
    "        passages = semantic_search(search_query, embeddings, edit['files'])\n",
    "    \n",
    "    # Fall back to text search if no results or no embeddings\n",
    "    if not passages and text_files:\n",
    "        print(\"  Falling back to text search...\")\n",
    "        passages = text_search(search_query, text_files, edit['files'])\n",
    "    \n",
    "    if not passages:\n",
    "        print(f\"  No relevant passages found for {edit_id}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"  Found {len(passages)} relevant passages\")\n",
    "    \n",
    "    # Generate acknowledgment and citation\n",
    "    acknowledgment_info = generate_acknowledgment(edit, passages, text_files)\n",
    "    \n",
    "    results[edit_id] = {\n",
    "        \"edit_comment\": edit['comment'],\n",
    "        \"context\": edit['context'],\n",
    "        \"section\": edit['section'],\n",
    "        \"acknowledgment\": acknowledgment_info.get(\"acknowledgment\", \"\"),\n",
    "        \"bibliography\": acknowledgment_info.get(\"bibliography\", []),\n",
    "        \"passages\": passages\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating citation report...\n",
      "Acknowledgment report generated: acknowledgment_suggestions.md\n",
      "\n",
      "You can now review the suggestions and incorporate them into your paper.\n"
     ]
    }
   ],
   "source": [
    "# Generate report\n",
    "print(\"\\nGenerating citation report...\")\n",
    "report_path = \"acknowledgment_suggestions.md\"\n",
    "\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# Acknowledgment Suggestions for Buddhist AI Paper\\n\\n\")\n",
    "    f.write(\"This report provides suggested acknowledgment sentences and citations based on Daniel's edit comments.\\n\\n\")\n",
    "    \n",
    "    for edit_id, info in results.items():\n",
    "        f.write(f\"## {edit_id.replace('_', ' ').title()}\\n\\n\")\n",
    "        f.write(f\"**Daniel's Comment:** {info['edit_comment']}\\n\\n\")\n",
    "        f.write(f\"**Context in Paper:** \\\"{info['context']}\\\"\\n\\n\")\n",
    "        f.write(f\"**Section:** {info['section']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"### Suggested Acknowledgment\\n\\n\")\n",
    "        f.write(f\"{info['acknowledgment']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"### Bibliography Entries\\n\\n\")\n",
    "        for entry in info['bibliography']:\n",
    "            f.write(f\"* {entry}\\n\")\n",
    "        \n",
    "        f.write(\"\\n---\\n\\n\")\n",
    "\n",
    "print(f\"Acknowledgment report generated: {report_path}\")\n",
    "print(\"\\nYou can now review the suggestions and incorporate them into your paper.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Display Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample result for 'buddhist_epistemology':\n",
      "\n",
      "Suggested acknowledgment:\n",
      "The notion that meaning emerges from relational patterns rather than discrete facts has been explored in Buddhist epistemology, particularly in Dharmakīrti's apoha theory which examines meaning as exclusion (Siderits, Tillemans, and Chakrabarti 2011; Dunne 2011). While a full treatment is beyond the scope of this paper, these works provide valuable context for considering the epistemological implications of vector space models.\n",
      "\n",
      "Bibliography entries:\n",
      "- Dunne, John D. 2011. \"Key Features of Dharmakīrti's Apoha Theory.\" In Apoha: Buddhist Nominalism and Human Cognition, edited by Mark Siderits, Tom Tillemans, and Arindam Chakrabarti, 84-108. New York: Columbia University Press.\n",
      "- Siderits, Mark, Tom Tillemans, and Arindam Chakrabarti, eds. 2011. Apoha: Buddhist Nominalism and Human Cognition. New York: Columbia University Press.\n"
     ]
    }
   ],
   "source": [
    "# Display a sample result if available\n",
    "if results:\n",
    "    sample_key = list(results.keys())[0]\n",
    "    print(f\"Sample result for '{sample_key}':\")\n",
    "    print(\"\\nSuggested acknowledgment:\")\n",
    "    print(results[sample_key][\"acknowledgment\"])\n",
    "    print(\"\\nBibliography entries:\")\n",
    "    for entry in results[sample_key][\"bibliography\"]:\n",
    "        print(f\"- {entry}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
